{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-niger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.0.dev6 (SDL 2.0.10, python 3.8.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "ep 1:  episode reward total was 1.000000. running mean: 1.000000\n",
      "ep 2:  episode reward total was 0.000000. running mean: 0.990000\n",
      "ep 3:  episode reward total was 0.000000. running mean: 0.980100\n",
      "ep 4:  episode reward total was 0.000000. running mean: 0.970299\n",
      "ep 5:  episode reward total was 1.000000. running mean: 0.970596\n",
      "ep 6:  episode reward total was 2.000000. running mean: 0.980890\n",
      "ep 7:  episode reward total was 0.000000. running mean: 0.971081\n",
      "ep 8:  episode reward total was 2.000000. running mean: 0.981370\n",
      "ep 9:  episode reward total was 0.000000. running mean: 0.971557\n",
      "ep 10:  episode reward total was 1.000000. running mean: 0.971841\n",
      "ep 11:  episode reward total was 0.000000. running mean: 0.962123\n",
      "ep 12:  episode reward total was 0.000000. running mean: 0.952501\n",
      "ep 13:  episode reward total was 0.000000. running mean: 0.942976\n",
      "ep 14:  episode reward total was 0.000000. running mean: 0.933547\n",
      "ep 15:  episode reward total was 1.000000. running mean: 0.934211\n",
      "ep 16:  episode reward total was 0.000000. running mean: 0.924869\n",
      "ep 17:  episode reward total was 1.000000. running mean: 0.925620\n",
      "ep 18:  episode reward total was 2.000000. running mean: 0.936364\n",
      "ep 19:  episode reward total was 1.000000. running mean: 0.937001\n",
      "ep 20:  episode reward total was 1.000000. running mean: 0.937631\n",
      "ep 21:  episode reward total was 1.000000. running mean: 0.938254\n",
      "ep 22:  episode reward total was 1.000000. running mean: 0.938872\n",
      "ep 23:  episode reward total was 2.000000. running mean: 0.949483\n",
      "ep 24:  episode reward total was 1.000000. running mean: 0.949988\n",
      "ep 25:  episode reward total was 2.000000. running mean: 0.960488\n",
      "ep 26:  episode reward total was 1.000000. running mean: 0.960883\n",
      "ep 27:  episode reward total was 1.000000. running mean: 0.961275\n",
      "ep 28:  episode reward total was 2.000000. running mean: 0.971662\n",
      "ep 29:  episode reward total was 1.000000. running mean: 0.971945\n",
      "ep 30:  episode reward total was 1.000000. running mean: 0.972226\n",
      "ep 31:  episode reward total was 1.000000. running mean: 0.972503\n",
      "ep 32:  episode reward total was 1.000000. running mean: 0.972778\n",
      "ep 33:  episode reward total was 2.000000. running mean: 0.983051\n",
      "ep 34:  episode reward total was 2.000000. running mean: 0.993220\n",
      "ep 35:  episode reward total was 2.000000. running mean: 1.003288\n",
      "ep 36:  episode reward total was 2.000000. running mean: 1.013255\n",
      "ep 37:  episode reward total was 2.000000. running mean: 1.023123\n",
      "ep 38:  episode reward total was 2.000000. running mean: 1.032891\n",
      "ep 39:  episode reward total was 2.000000. running mean: 1.042562\n",
      "ep 40:  episode reward total was 2.000000. running mean: 1.052137\n",
      "ep 41:  episode reward total was 0.000000. running mean: 1.041615\n",
      "ep 42:  episode reward total was 2.000000. running mean: 1.051199\n",
      "ep 43:  episode reward total was 2.000000. running mean: 1.060687\n",
      "ep 44:  episode reward total was 0.000000. running mean: 1.050080\n",
      "ep 45:  episode reward total was 2.000000. running mean: 1.059580\n",
      "ep 46:  episode reward total was 2.000000. running mean: 1.068984\n",
      "ep 47:  episode reward total was 2.000000. running mean: 1.078294\n",
      "ep 48:  episode reward total was 2.000000. running mean: 1.087511\n",
      "ep 49:  episode reward total was 2.000000. running mean: 1.096636\n",
      "ep 50:  episode reward total was 2.000000. running mean: 1.105670\n",
      "ep 51:  episode reward total was 2.000000. running mean: 1.114613\n",
      "ep 52:  episode reward total was 2.000000. running mean: 1.123467\n",
      "ep 53:  episode reward total was 2.000000. running mean: 1.132232\n",
      "ep 54:  episode reward total was 2.000000. running mean: 1.140910\n",
      "ep 55:  episode reward total was 3.000000. running mean: 1.159501\n",
      "ep 56:  episode reward total was 2.000000. running mean: 1.167906\n",
      "ep 57:  episode reward total was 3.000000. running mean: 1.186227\n",
      "ep 58:  episode reward total was 2.000000. running mean: 1.194364\n",
      "ep 59:  episode reward total was 2.000000. running mean: 1.202421\n",
      "ep 60:  episode reward total was 2.000000. running mean: 1.210396\n",
      "ep 61:  episode reward total was 2.000000. running mean: 1.218292\n",
      "ep 62:  episode reward total was 2.000000. running mean: 1.226110\n",
      "ep 63:  episode reward total was 2.000000. running mean: 1.233848\n",
      "ep 64:  episode reward total was 3.000000. running mean: 1.251510\n",
      "ep 65:  episode reward total was 3.000000. running mean: 1.268995\n",
      "ep 66:  episode reward total was 3.000000. running mean: 1.286305\n",
      "ep 67:  episode reward total was 3.000000. running mean: 1.303442\n",
      "ep 68:  episode reward total was 3.000000. running mean: 1.320407\n",
      "ep 69:  episode reward total was 3.000000. running mean: 1.337203\n",
      "ep 70:  episode reward total was 2.000000. running mean: 1.343831\n",
      "ep 71:  episode reward total was 3.000000. running mean: 1.360393\n",
      "ep 72:  episode reward total was 3.000000. running mean: 1.376789\n",
      "ep 73:  episode reward total was 3.000000. running mean: 1.393021\n",
      "ep 74:  episode reward total was 3.000000. running mean: 1.409091\n",
      "ep 75:  episode reward total was 3.000000. running mean: 1.425000\n",
      "ep 76:  episode reward total was 2.000000. running mean: 1.430750\n",
      "ep 77:  episode reward total was 3.000000. running mean: 1.446443\n",
      "ep 78:  episode reward total was 3.000000. running mean: 1.461978\n",
      "ep 79:  episode reward total was 3.000000. running mean: 1.477358\n",
      "ep 80:  episode reward total was 3.000000. running mean: 1.492585\n",
      "ep 81:  episode reward total was 2.000000. running mean: 1.497659\n",
      "ep 82:  episode reward total was 1.000000. running mean: 1.492682\n",
      "ep 83:  episode reward total was 2.000000. running mean: 1.497756\n",
      "ep 84:  episode reward total was 7.000000. running mean: 1.552778\n",
      "ep 85:  episode reward total was 2.000000. running mean: 1.557250\n",
      "ep 86:  episode reward total was 2.000000. running mean: 1.561678\n",
      "ep 87:  episode reward total was 2.000000. running mean: 1.566061\n",
      "ep 88:  episode reward total was 2.000000. running mean: 1.570400\n",
      "ep 89:  episode reward total was 2.000000. running mean: 1.574696\n",
      "ep 90:  episode reward total was 2.000000. running mean: 1.578949\n",
      "ep 91:  episode reward total was 4.000000. running mean: 1.603160\n",
      "ep 92:  episode reward total was 7.000000. running mean: 1.657128\n",
      "ep 93:  episode reward total was 2.000000. running mean: 1.660557\n",
      "ep 94:  episode reward total was 2.000000. running mean: 1.663951\n",
      "ep 95:  episode reward total was 2.000000. running mean: 1.667312\n",
      "ep 96:  episode reward total was 2.000000. running mean: 1.670639\n",
      "ep 97:  episode reward total was 3.000000. running mean: 1.683932\n",
      "ep 98:  episode reward total was 3.000000. running mean: 1.697093\n",
      "ep 99:  episode reward total was 3.000000. running mean: 1.710122\n",
      "ep 100:  episode reward total was 3.000000. running mean: 1.723021\n",
      "ep 101:  episode reward total was 3.000000. running mean: 1.735791\n",
      "ep 102:  episode reward total was 3.000000. running mean: 1.748433\n",
      "ep 103:  episode reward total was 7.000000. running mean: 1.800948\n",
      "ep 104:  episode reward total was 3.000000. running mean: 1.812939\n",
      "ep 105:  episode reward total was 3.000000. running mean: 1.824810\n",
      "ep 106:  episode reward total was 3.000000. running mean: 1.836561\n",
      "ep 107:  episode reward total was 0.000000. running mean: 1.818196\n",
      "ep 108:  episode reward total was 3.000000. running mean: 1.830014\n",
      "ep 109:  episode reward total was 7.000000. running mean: 1.881714\n",
      "ep 110:  episode reward total was 3.000000. running mean: 1.892897\n",
      "ep 111:  episode reward total was 7.000000. running mean: 1.943968\n",
      "ep 112:  episode reward total was 12.000000. running mean: 2.044528\n",
      "ep 113:  episode reward total was 3.000000. running mean: 2.054083\n",
      "ep 114:  episode reward total was 15.000000. running mean: 2.183542\n",
      "ep 115:  episode reward total was 14.000000. running mean: 2.301706\n",
      "ep 116:  episode reward total was 11.000000. running mean: 2.388689\n",
      "ep 117:  episode reward total was 10.000000. running mean: 2.464803\n",
      "ep 118:  episode reward total was 1.000000. running mean: 2.450154\n",
      "ep 119:  episode reward total was 9.000000. running mean: 2.515653\n",
      "ep 120:  episode reward total was 12.000000. running mean: 2.610496\n",
      "ep 121:  episode reward total was 10.000000. running mean: 2.684391\n",
      "ep 122:  episode reward total was 14.000000. running mean: 2.797548\n",
      "ep 123:  episode reward total was 3.000000. running mean: 2.799572\n",
      "ep 124:  episode reward total was 7.000000. running mean: 2.841576\n",
      "ep 125:  episode reward total was 10.000000. running mean: 2.913161\n",
      "ep 126:  episode reward total was 7.000000. running mean: 2.954029\n",
      "ep 127:  episode reward total was 6.000000. running mean: 2.984489\n",
      "ep 128:  episode reward total was 15.000000. running mean: 3.104644\n",
      "ep 129:  episode reward total was 12.000000. running mean: 3.193597\n",
      "ep 130:  episode reward total was 23.000000. running mean: 3.391661\n",
      "ep 131:  episode reward total was 15.000000. running mean: 3.507745\n",
      "ep 132:  episode reward total was 7.000000. running mean: 3.542667\n",
      "ep 133:  episode reward total was 30.000000. running mean: 3.807241\n",
      "ep 134:  episode reward total was 25.000000. running mean: 4.019168\n",
      "ep 135:  episode reward total was 6.000000. running mean: 4.038977\n",
      "ep 136:  episode reward total was 17.000000. running mean: 4.168587\n",
      "ep 137:  episode reward total was 27.000000. running mean: 4.396901\n",
      "ep 138:  episode reward total was 15.000000. running mean: 4.502932\n",
      "ep 139:  episode reward total was 7.000000. running mean: 4.527903\n",
      "ep 140:  episode reward total was 12.000000. running mean: 4.602624\n",
      "ep 141:  episode reward total was 7.000000. running mean: 4.626597\n",
      "ep 142:  episode reward total was 23.000000. running mean: 4.810331\n",
      "ep 143:  episode reward total was 3.000000. running mean: 4.792228\n",
      "ep 144:  episode reward total was 8.000000. running mean: 4.824306\n",
      "ep 145:  episode reward total was 3.000000. running mean: 4.806063\n",
      "ep 146:  episode reward total was 20.000000. running mean: 4.958002\n",
      "ep 147:  episode reward total was 5.000000. running mean: 4.958422\n",
      "ep 148:  episode reward total was 5.000000. running mean: 4.958838\n",
      "ep 149:  episode reward total was 25.000000. running mean: 5.159249\n",
      "ep 150:  episode reward total was 1.000000. running mean: 5.117657\n",
      "ep 151:  episode reward total was 9.000000. running mean: 5.156480\n",
      "ep 152:  episode reward total was 11.000000. running mean: 5.214916\n",
      "ep 153:  episode reward total was 18.000000. running mean: 5.342766\n",
      "ep 154:  episode reward total was 5.000000. running mean: 5.339339\n",
      "ep 155:  episode reward total was 13.000000. running mean: 5.415945\n",
      "ep 156:  episode reward total was 20.000000. running mean: 5.561786\n",
      "ep 157:  episode reward total was 5.000000. running mean: 5.556168\n",
      "ep 158:  episode reward total was 19.000000. running mean: 5.690606\n",
      "ep 159:  episode reward total was 9.000000. running mean: 5.723700\n",
      "ep 160:  episode reward total was 9.000000. running mean: 5.756463\n",
      "ep 161:  episode reward total was 27.000000. running mean: 5.968899\n",
      "ep 162:  episode reward total was 14.000000. running mean: 6.049210\n",
      "ep 163:  episode reward total was 29.000000. running mean: 6.278718\n",
      "ep 164:  episode reward total was 32.000000. running mean: 6.535930\n",
      "ep 165:  episode reward total was 23.000000. running mean: 6.700571\n",
      "ep 166:  episode reward total was 24.000000. running mean: 6.873565\n",
      "ep 167:  episode reward total was 30.000000. running mean: 7.104830\n",
      "ep 168:  episode reward total was 32.000000. running mean: 7.353781\n",
      "ep 169:  episode reward total was 22.000000. running mean: 7.500244\n",
      "ep 170:  episode reward total was 13.000000. running mean: 7.555241\n",
      "ep 171:  episode reward total was 30.000000. running mean: 7.779689\n",
      "ep 172:  episode reward total was 26.000000. running mean: 7.961892\n",
      "ep 173:  episode reward total was 25.000000. running mean: 8.132273\n",
      "ep 174:  episode reward total was 26.000000. running mean: 8.310950\n",
      "ep 175:  episode reward total was 28.000000. running mean: 8.507841\n",
      "ep 176:  episode reward total was 30.000000. running mean: 8.722762\n",
      "ep 177:  episode reward total was 3.000000. running mean: 8.665535\n",
      "ep 178:  episode reward total was 3.000000. running mean: 8.608879\n",
      "ep 179:  episode reward total was 19.000000. running mean: 8.712791\n",
      "ep 180:  episode reward total was 23.000000. running mean: 8.855663\n",
      "ep 181:  episode reward total was 27.000000. running mean: 9.037106\n",
      "ep 182:  episode reward total was 26.000000. running mean: 9.206735\n",
      "ep 183:  episode reward total was 3.000000. running mean: 9.144668\n",
      "ep 184:  episode reward total was 2.000000. running mean: 9.073221\n",
      "ep 185:  episode reward total was 19.000000. running mean: 9.172489\n",
      "ep 186:  episode reward total was 15.000000. running mean: 9.230764\n",
      "ep 187:  episode reward total was 7.000000. running mean: 9.208456\n",
      "ep 188:  episode reward total was 11.000000. running mean: 9.226372\n",
      "ep 189:  episode reward total was 11.000000. running mean: 9.244108\n",
      "ep 190:  episode reward total was 7.000000. running mean: 9.221667\n",
      "ep 191:  episode reward total was 30.000000. running mean: 9.429450\n",
      "ep 192:  episode reward total was 31.000000. running mean: 9.645156\n",
      "ep 193:  episode reward total was 16.000000. running mean: 9.708704\n",
      "ep 194:  episode reward total was 38.000000. running mean: 9.991617\n",
      "ep 195:  episode reward total was 40.000000. running mean: 10.291701\n",
      "ep 196:  episode reward total was 38.000000. running mean: 10.568784\n",
      "ep 197:  episode reward total was 37.000000. running mean: 10.833096\n",
      "ep 198:  episode reward total was 40.000000. running mean: 11.124765\n",
      "ep 199:  episode reward total was 39.000000. running mean: 11.403517\n",
      "ep 200:  episode reward total was 25.000000. running mean: 11.539482\n",
      "ep 201:  episode reward total was 30.000000. running mean: 11.724087\n",
      "ep 202:  episode reward total was 37.000000. running mean: 11.976847\n",
      "ep 203:  episode reward total was 41.000000. running mean: 12.267078\n",
      "ep 204:  episode reward total was 37.000000. running mean: 12.514407\n",
      "ep 205:  episode reward total was 31.000000. running mean: 12.699263\n",
      "ep 206:  episode reward total was 38.000000. running mean: 12.952271\n",
      "ep 207:  episode reward total was 41.000000. running mean: 13.232748\n",
      "ep 208:  episode reward total was 40.000000. running mean: 13.500420\n",
      "ep 209:  episode reward total was 42.000000. running mean: 13.785416\n",
      "ep 210:  episode reward total was 1.000000. running mean: 13.657562\n",
      "ep 211:  episode reward total was 22.000000. running mean: 13.740986\n",
      "ep 212:  episode reward total was 30.000000. running mean: 13.903577\n",
      "ep 213:  episode reward total was 42.000000. running mean: 14.184541\n",
      "ep 214:  episode reward total was 42.000000. running mean: 14.462695\n",
      "ep 215:  episode reward total was 41.000000. running mean: 14.728068\n",
      "ep 216:  episode reward total was 42.000000. running mean: 15.000788\n",
      "ep 217:  episode reward total was 42.000000. running mean: 15.270780\n",
      "ep 218:  episode reward total was 43.000000. running mean: 15.548072\n",
      "ep 219:  episode reward total was 38.000000. running mean: 15.772591\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import sys, os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import _pickle as pickle\n",
    "from grid_world import grid_world\n",
    "from policy_gradient import network\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "env=grid_world()\n",
    "observation=env.reset()\n",
    "xlen=env.xlen\n",
    "ylen=env.ylen\n",
    "\n",
    "pg=network(xlen*ylen,200,4)\n",
    "\n",
    "reward_sum=0\n",
    "running_reward = None\n",
    "prev_x = 0\n",
    "episode_number=0\n",
    "\n",
    "while True:\n",
    "    #env.render()\n",
    "    prev_pos=observation\n",
    "    x = np.zeros(shape=(xlen* ylen), dtype=np.int)\n",
    "    x[observation[1]*xlen + observation[0]] = 1\n",
    "    x[env.reward_pos[1]*xlen + env.reward_pos[0]] = 1\n",
    "\n",
    "\n",
    "    #今のネズミの位置\n",
    "    prev_pos = observation\n",
    "\n",
    "\n",
    "    #チーズの位置\n",
    "    prev_reward_pos = env.reward_pos\n",
    "\n",
    "    aprob=pg.forward(x)\n",
    "    action = pg.select_action(aprob)\n",
    "    observation,reward,done=env.step(action)\n",
    "    reward_pos=env.reward_pos\n",
    "    agent_pos=observation\n",
    "    reward_sum += reward\n",
    "    p_pos=abs(reward_pos[0]-prev_pos[0])+abs(reward_pos[1]-prev_pos[1])\n",
    "    c_pos=abs(reward_pos[0]-agent_pos[0])+abs(reward_pos[1]-agent_pos[1])\n",
    "    if p_pos>c_pos:\n",
    "        reward+=1\n",
    "    else:\n",
    "        reward-=1\n",
    "\n",
    "    pg.record_reward(reward)\n",
    "\n",
    "\n",
    "    if done:\n",
    "        episode_number += 1\n",
    "\n",
    "        if reward_sum != 0:\n",
    "            pg.backward()\n",
    "\n",
    "        if episode_number % pg.batch_size == 0:\n",
    "            pg.update()\n",
    "\n",
    "        running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "        print ('ep %d:  episode reward total was %f. running mean: %f'\n",
    "             % (episode_number, reward_sum, running_reward))\n",
    "\n",
    "        reward_sum = 0\n",
    "        observation = env.reset() # reset env\n",
    "        \n",
    "\n",
    "    #pygame.display.flip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-buffer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
